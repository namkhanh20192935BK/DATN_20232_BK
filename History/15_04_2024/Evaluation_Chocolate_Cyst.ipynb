{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1674e46f",
   "metadata": {},
   "source": [
    "# Cài đặt và import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "#SAM\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "#Transformers\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "#Datasets to prepare data and monai if you want to use special loss functions\n",
    "!pip install datasets\n",
    "!pip install -q monai\n",
    "#Patchify to divide large images into smaller patches for training. (Not necessary for smaller images)\n",
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ae141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import os\n",
    "from patchify import patchify  #Only to handle large images\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e92a4",
   "metadata": {},
   "source": [
    "# Chia dataset để training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430c5dd",
   "metadata": {},
   "source": [
    "## Chia dataset cho tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96899b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục chứa các hình ảnh\n",
    "image_folder = \"/kaggle/input/otu2d-8layer/OTU2D_8_layers_splitted/Chocolate_Cyst/train/image\"\n",
    "\n",
    "# Lấy danh sách các tệp trong thư mục và sắp xếp theo thứ tự tên tăng dần từ A đến Z\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "\n",
    "# Khởi tạo một danh sách để chứa các hình ảnh dưới dạng mảng NumPy\n",
    "image_array_list = []\n",
    "\n",
    "# Lặp qua tất cả các tệp trong thư mục đã sắp xếp\n",
    "for filename in image_files:\n",
    "    # Kiểm tra xem tệp có phải là hình ảnh không\n",
    "    if filename.endswith(('.JPG')):\n",
    "        # Đường dẫn đầy đủ tới hình ảnh\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Đọc hình ảnh\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Kiểm tra xem hình ảnh có được đọc thành công hay không\n",
    "        if img is not None:\n",
    "            # Thêm hình ảnh vào danh sách\n",
    "            image_array_list.append(img)\n",
    "        else:\n",
    "            print(f\"Không thể đọc hình ảnh {filename}\")\n",
    "\n",
    "# Chuyển đổi danh sách hình ảnh thành mảng NumPy\n",
    "train_images_np = np.array(image_array_list)\n",
    "\n",
    "# In ra kích thước của mảng hình ảnh\n",
    "print(\"Kích thước của mảng hình ảnh:\", train_images_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục chứa các hình ảnh\n",
    "image_folder = \"/kaggle/input/otu2d-8layer/OTU2D_8_layers_splitted/Chocolate_Cyst/train/label\"\n",
    "\n",
    "# Lấy danh sách các tệp trong thư mục và sắp xếp theo thứ tự tên tăng dần từ A đến Z\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "\n",
    "# Khởi tạo một danh sách để chứa các hình ảnh dưới dạng mảng NumPy\n",
    "image_array_list = []\n",
    "\n",
    "# Lặp qua tất cả các tệp trong thư mục đã được sắp xếp\n",
    "for filename in image_files:\n",
    "    # Kiểm tra xem tệp có phải là hình ảnh không\n",
    "    if filename.endswith('.PNG'):\n",
    "        # Đường dẫn đầy đủ tới hình ảnh\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Đọc hình ảnh\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = img / 255.0\n",
    "        (thresh, img) = cv2.threshold(img, 0, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        # img = np.int32(img)\n",
    "\n",
    "        # Kiểm tra xem hình ảnh có được đọc thành công hay không\n",
    "        if img is not None:\n",
    "            # Thêm hình ảnh vào danh sách\n",
    "            image_array_list.append(img)\n",
    "        else:\n",
    "            print(f\"Không thể đọc hình ảnh {filename}\")\n",
    "\n",
    "# Chuyển đổi danh sách hình ảnh thành mảng NumPy\n",
    "train_labels_np = np.array(image_array_list)\n",
    "\n",
    "# In ra kích thước của mảng hình ảnh\n",
    "print(\"Kích thước của mảng mặt nạ:\", train_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de863d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy arrays to Pillow images and store them in a dictionary\n",
    "dataset_dict = {\n",
    "    \"image\": [Image.fromarray(img).convert('RGB') for img in train_images_np],\n",
    "    \"label\": [Image.fromarray(mask).convert('I') for mask in train_labels_np],\n",
    "}\n",
    "\n",
    "# Create the dataset using the datasets.Dataset class\n",
    "train_dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a09e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa568c",
   "metadata": {},
   "source": [
    "## Chia dataset cho tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4656bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục chứa các hình ảnh\n",
    "image_folder = \"/kaggle/input/otu2d-8layer/OTU2D_8_layers_splitted/Chocolate_Cyst/validation/image\"\n",
    "\n",
    "# Lấy danh sách các tệp trong thư mục và sắp xếp theo thứ tự tên tăng dần từ A đến Z\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "\n",
    "# Khởi tạo một danh sách để chứa các hình ảnh dưới dạng mảng NumPy\n",
    "image_array_list = []\n",
    "\n",
    "# Lặp qua tất cả các tệp trong thư mục đã sắp xếp\n",
    "for filename in image_files:\n",
    "    # Kiểm tra xem tệp có phải là hình ảnh không\n",
    "    if filename.endswith(('.JPG')):\n",
    "        # Đường dẫn đầy đủ tới hình ảnh\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Đọc hình ảnh\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Kiểm tra xem hình ảnh có được đọc thành công hay không\n",
    "        if img is not None:\n",
    "            # Thêm hình ảnh vào danh sách\n",
    "            image_array_list.append(img)\n",
    "        else:\n",
    "            print(f\"Không thể đọc hình ảnh {filename}\")\n",
    "\n",
    "# Chuyển đổi danh sách hình ảnh thành mảng NumPy\n",
    "val_images_np = np.array(image_array_list)\n",
    "\n",
    "# In ra kích thước của mảng hình ảnh\n",
    "print(\"Kích thước của mảng hình ảnh:\", val_images_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục chứa các hình ảnh\n",
    "image_folder = \"/kaggle/input/otu2d-8layer/OTU2D_8_layers_splitted/Chocolate_Cyst/validation/label\"\n",
    "\n",
    "# Lấy danh sách các tệp trong thư mục và sắp xếp theo thứ tự tên tăng dần từ A đến Z\n",
    "image_files = sorted(os.listdir(image_folder))\n",
    "\n",
    "# Khởi tạo một danh sách để chứa các hình ảnh dưới dạng mảng NumPy\n",
    "image_array_list = []\n",
    "\n",
    "# Lặp qua tất cả các tệp trong thư mục đã được sắp xếp\n",
    "for filename in image_files:\n",
    "    # Kiểm tra xem tệp có phải là hình ảnh không\n",
    "    if filename.endswith('.PNG'):\n",
    "        # Đường dẫn đầy đủ tới hình ảnh\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Đọc hình ảnh\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = img / 255.0\n",
    "        (thresh, img) = cv2.threshold(img, 0, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        # img = np.int32(img)\n",
    "\n",
    "        # Kiểm tra xem hình ảnh có được đọc thành công hay không\n",
    "        if img is not None:\n",
    "            # Thêm hình ảnh vào danh sách\n",
    "            image_array_list.append(img)\n",
    "        else:\n",
    "            print(f\"Không thể đọc hình ảnh {filename}\")\n",
    "\n",
    "# Chuyển đổi danh sách hình ảnh thành mảng NumPy\n",
    "val_labels_np = np.array(image_array_list)\n",
    "\n",
    "# In ra kích thước của mảng hình ảnh\n",
    "print(\"Kích thước của mảng mặt nạ:\", val_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy arrays to Pillow images and store them in a dictionary\n",
    "dataset_dict = {\n",
    "    \"image\": [Image.fromarray(img).convert('RGB') for img in val_images_np],\n",
    "    \"label\": [Image.fromarray(mask).convert('I') for mask in val_labels_np],\n",
    "}\n",
    "\n",
    "# Create the dataset using the datasets.Dataset class\n",
    "val_dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1e5d6",
   "metadata": {},
   "source": [
    "# Kiểm tra ảnh và mặt nạ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda57bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = random.randint(0, train_images_np.shape[0]-1)\n",
    "example = train_dataset[img_num]\n",
    "image = example[\"image\"]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = train_dataset[img_num][\"image\"]\n",
    "example_mask = train_dataset[img_num][\"label\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the first image on the left\n",
    "axes[0].imshow(np.array(example_image), cmap='gray')  # Assuming the first image is grayscale\n",
    "axes[0].set_title(\"Image\")\n",
    "\n",
    "# Plot the second image on the right\n",
    "axes[1].imshow(example_mask, cmap='gray')  # Assuming the second image is grayscale\n",
    "axes[1].set_title(\"Mask\")\n",
    "\n",
    "# Hide axis ticks and labels\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Display the images side by side\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e66fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.2])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.imshow(np.array(image))\n",
    "ground_truth_seg = np.array(example[\"label\"])\n",
    "show_mask(ground_truth_seg, axes)\n",
    "axes.title.set_text(f\"Ground truth mask\")\n",
    "axes.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373370e7",
   "metadata": {},
   "source": [
    "# Vẽ bounding boxes cho mặt nạ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41665b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get bounding boxes from mask.\n",
    "def get_bounding_box(ground_truth_map):\n",
    "  # get bounding box from mask\n",
    "  y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "  x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "  y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "  # add perturbation to bounding box coordinates\n",
    "  H, W = ground_truth_map.shape\n",
    "  x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "  x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "  y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "  y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "  bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "  return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1faa6",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be687bdc",
   "metadata": {},
   "source": [
    "## Hàm tạo 1 dataset input images and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187133be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SAMDataset(Dataset):\n",
    "  \"\"\"\n",
    "  This class is used to create a dataset that serves input images and masks.\n",
    "  It takes a dataset and a processor as input and overrides the __len__ and __getitem__ methods of the Dataset class.\n",
    "  \"\"\"\n",
    "  def __init__(self, dataset, processor):\n",
    "    self.dataset = dataset\n",
    "    self.processor = processor\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = self.dataset[idx]\n",
    "    image = item[\"image\"]\n",
    "    ground_truth_mask = np.array(item[\"label\"])\n",
    "\n",
    "    # get bounding box prompt | vẽ box cho mặt nạ\n",
    "    prompt = get_bounding_box(ground_truth_mask)\n",
    "\n",
    "    # prepare image and prompt for the model | Chuẩn bị mặt nạ và hộp giới hạn\n",
    "    inputs = self.processor(image, input_boxes=[[prompt]], return_tensors=\"pt\")\n",
    "\n",
    "    # remove batch dimension which the processor adds by default | Loại bỏ chiều Batch được thêm vào mặc định\n",
    "    inputs = {k:v.squeeze(0) for k,v in inputs.items()}\n",
    "\n",
    "    # add ground truth segmentation | Thêm ground truth để đánh giá việc Segment sau này, đánh giá hiệu suất mô hình\n",
    "    inputs[\"ground_truth_mask\"] = ground_truth_mask\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065324e",
   "metadata": {},
   "source": [
    "## Load model SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b520d",
   "metadata": {},
   "source": [
    "### Xử lý dữ liệu để tương thích với đầu vào Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6942a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "from transformers import SamProcessor\n",
    "processor = SamProcessor.from_pretrained(\"wanglab/medsam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6588c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SAMDataseta\n",
    "train_dataset = SAMDataset(dataset=train_dataset, processor=processor)\n",
    "val_dataset = SAMDataset(dataset=val_dataset, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_dataset[0]\n",
    "for k,v in example.items():\n",
    "  print(f'{k}: {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = val_dataset[0]\n",
    "for k,v in example.items():\n",
    "  print(f'{k}: {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader instance for the training dataset\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k,v in batch.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "for k,v in batch.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"ground_truth_mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e072929",
   "metadata": {},
   "source": [
    "### Load model Pretrained của Segment Anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from transformers import SamModel\n",
    "model = SamModel.from_pretrained(\"wanglab/medsam-vit-base\")\n",
    "\n",
    "# make sure we only compute gradients for mask decoder\n",
    "for name, param in model.named_parameters():\n",
    "  if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254c1b5",
   "metadata": {},
   "source": [
    "### Khởi tạo model với hàm tối ưu là Adam, hàm loss là DiceCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d46c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from monai.losses import DiceLoss, DiceCELoss, DiceFocalLoss\n",
    "\n",
    "# Khởi tạo optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=0)\n",
    "\n",
    "# Sử dụng DiceCELoss\n",
    "seg_loss = DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')\n",
    "\n",
    "# Sử dụng DiceFocalLoss\n",
    "# seg_loss = DiceFocalLoss(sigmoid=True, gamma=0.25)\n",
    "\n",
    "# Sử dụng DiceLoss\n",
    "# seg_loss = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de857716",
   "metadata": {},
   "source": [
    "### Load hàm loss đánh giá model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc54e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "import torch\n",
    "from torch.nn.functional import threshold, normalize\n",
    "\n",
    "smooth=1e-10\n",
    "\n",
    "# Define functions for calculating evaluation metrics\n",
    "def dice(predicted, target):\n",
    "    true_positive = torch.sum(predicted * target)\n",
    "    false_negative = torch.sum(target) - true_positive\n",
    "    false_positive = torch.sum(predicted) - true_positive\n",
    "    return (2. * true_positive + smooth) / (2. *true_positive + false_negative + false_positive + smooth)\n",
    "\n",
    "def iou(predicted, target):\n",
    "    intersection = torch.sum(predicted * target)\n",
    "    union = torch.sum(predicted) + torch.sum(target) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def recall(predicted, target):\n",
    "    true_positive = torch.sum(predicted * target)\n",
    "    false_negative = torch.sum(target) - true_positive\n",
    "    return (true_positive + smooth) / (true_positive + false_negative + smooth)\n",
    "\n",
    "def precision(predicted, target):\n",
    "    true_positive = torch.sum(predicted * target)\n",
    "    false_positive = torch.sum(predicted) - true_positive\n",
    "    return (true_positive + smooth) / (true_positive + false_positive + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831d2e4",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ce061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "import torch\n",
    "from torch.nn.functional import threshold, normalize\n",
    "import os\n",
    "\n",
    "# Tạo thư mục checkpoint\n",
    "checkpoint_dir = '/kaggle/working/checkpoint_MEDSAM'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Biến để theo dõi loss tốt nhất và trọng số của nó\n",
    "best_loss = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# Add list to record loss of train dataset\n",
    "train_loss_list = []\n",
    "train_dice_loss = []\n",
    "train_iou_loss = []\n",
    "train_precision_loss = []\n",
    "train_recall_loss = []\n",
    "\n",
    "# Add list to record loss of validation dataset\n",
    "val_loss_list = []\n",
    "val_dice_loss = []\n",
    "val_iou_loss = []\n",
    "val_precision_loss = []\n",
    "val_recall_loss = []\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 15  # Số lượng epochs mà mô hình không cải thiện trước khi dừng sớm\n",
    "counter = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Train Model on Train Dataset\n",
    "    epoch_losses = []\n",
    "    train_dice_scores = []\n",
    "    train_iou_scores = []\n",
    "    train_recall_scores = []\n",
    "    train_precision_scores = []\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # forward pass\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                        input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                        multimask_output=False)\n",
    "\n",
    "        # compute loss\n",
    "        predicted_masks = outputs.pred_masks.squeeze(1)\n",
    "        ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "        loss = seg_loss(predicted_masks, ground_truth_masks.unsqueeze(1))\n",
    "\n",
    "        # backward pass (compute gradients of parameters w.r.t. loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        \n",
    "        predicted_masks_eval = (outputs.pred_masks.squeeze() > 0.5).float() \n",
    "        train_dice_scores.append(dice(predicted_masks_eval, ground_truth_masks))\n",
    "        train_iou_scores.append(iou(predicted_masks_eval, ground_truth_masks))\n",
    "        train_recall_scores.append(recall(predicted_masks_eval, ground_truth_masks))\n",
    "        train_precision_scores.append(precision(predicted_masks_eval, ground_truth_masks))\n",
    "\n",
    "    # Lưu trọng số của mô hình sau mỗi epoch vào thư mục checkpoint\n",
    "    if epoch == num_epochs - 1:\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'model_epoch_{epoch}_MedSAM.pt'))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'model_epoch_final_MedSAM.pt'))\n",
    "\n",
    "    # Tính loss trung bình và accuracy của epoch hiện tại\n",
    "    epoch_loss_mean = mean(epoch_losses)\n",
    "    train_loss_list.append(epoch_loss_mean)\n",
    "    \n",
    "    train_dice = torch.tensor(train_dice_scores).mean().item()\n",
    "    train_iou = torch.tensor(train_iou_scores).mean().item()\n",
    "    train_recall = torch.tensor(train_recall_scores).mean().item()\n",
    "    train_precision = torch.tensor(train_precision_scores).mean().item()\n",
    "    \n",
    "    train_dice_loss.append(train_dice)\n",
    "    train_iou_loss.append(train_iou)\n",
    "    train_recall_loss.append(train_recall)\n",
    "    train_precision_loss.append(train_precision)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # Đánh giá mô hình trên tập validation\n",
    "    validation_losses = []\n",
    "    val_dice_scores = []\n",
    "    val_iou_scores = []\n",
    "    val_recall_scores = []\n",
    "    val_precision_scores = []\n",
    "    \n",
    "    with torch.no_grad():  # Không tính gradient trong quá trình đánh giá\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                            input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                            multimask_output=False)\n",
    "            predicted_masks = outputs.pred_masks.squeeze(1)\n",
    "            ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "            loss = seg_loss(predicted_masks, ground_truth_masks.unsqueeze(1))\n",
    "            validation_losses.append(loss.item())\n",
    "            \n",
    "            predicted_masks_eval = (outputs.pred_masks.squeeze() > 0.5).float() \n",
    "            val_dice_scores.append(dice(predicted_masks_eval, ground_truth_masks))\n",
    "            val_iou_scores.append(iou(predicted_masks_eval, ground_truth_masks))\n",
    "            val_recall_scores.append(recall(predicted_masks_eval, ground_truth_masks))\n",
    "            val_precision_scores.append(precision(predicted_masks_eval, ground_truth_masks))\n",
    "\n",
    "    # Tính loss trung bình trên tập validation\n",
    "    validation_loss_mean = mean(validation_losses)\n",
    "    val_loss_list.append(validation_loss_mean)\n",
    "    \n",
    "    val_dice = torch.tensor(val_dice_scores).mean().item()\n",
    "    val_iou = torch.tensor(val_iou_scores).mean().item()\n",
    "    val_recall = torch.tensor(val_recall_scores).mean().item()\n",
    "    val_precision = torch.tensor(val_precision_scores).mean().item()\n",
    "    \n",
    "    val_dice_loss.append(val_dice)\n",
    "    val_iou_loss.append(val_iou)\n",
    "    val_recall_loss.append(val_recall)\n",
    "    val_precision_loss.append(val_precision)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # In thông tin về epoch, loss của tập train và validation\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    print(f'Train Mean loss: {epoch_loss_mean:.4f}')\n",
    "    print(f'Train Dice: {train_dice:.4f}')\n",
    "    print(f'Train IOU: {train_iou:.4f}')\n",
    "    print(f'Train Recall: {train_recall:.4f}')\n",
    "    print(f'Train Precision: {train_precision:.4f}')\n",
    "    print('----------------------')\n",
    "    print(f'Validation Mean loss: {validation_loss_mean:.4f}')\n",
    "    print(f'Validation Dice: {val_dice:.4f}')\n",
    "    print(f'Validation IOU: {val_iou:.4f}')\n",
    "    print(f'Validation Recall: {val_recall:.4f}')\n",
    "    print(f'Validation Precision: {val_precision:.4f}')\n",
    "\n",
    "    # Kiểm tra xem loss của epoch hiện tại có là tốt nhất không\n",
    "    if validation_loss_mean < best_loss:\n",
    "    # Nếu là loss tốt nhất, cập nhật biến best_loss và lưu trọng số tốt nhất\n",
    "        best_loss = validation_loss_mean\n",
    "        best_weights = model.state_dict()\n",
    "        torch.save(best_weights, os.path.join(checkpoint_dir, 'best_model_weights_Chocolate_Cyst.pt'))\n",
    "        print(\"Best model weights saved.\")\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # Kiểm tra early stopping\n",
    "    if epoch > 0:  # Bắt đầu kiểm tra early stopping sau epoch đầu tiên\n",
    "        if validation_loss_mean >= prev_epoch_loss:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping! No improvement in {patience} epochs.\")\n",
    "                break\n",
    "        else:\n",
    "            counter = 0  # Reset counter\n",
    "            prev_epoch_loss = validation_loss_mean  # Lưu loss của epoch hiện tại để so sánh với epoch tiếp theo\n",
    "    else:\n",
    "        prev_epoch_loss = validation_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bda89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa433387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffeee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d45c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e36f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65436bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_recall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_precision_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def61450",
   "metadata": {},
   "source": [
    "# Draw chart for loss between train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "loss = np.arange(epoch + 1)\n",
    "\n",
    "# Biểu đồ mean loss\n",
    "plt.plot(loss, train_loss_list, label='Training Loss')\n",
    "plt.plot(loss, val_loss_list, label='Validation Loss') \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ca7a9",
   "metadata": {},
   "source": [
    "### Draw chart for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ecd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.arange(epoch + 1)\n",
    "\n",
    "# Biểu đồ mean loss\n",
    "plt.plot(loss, train_dice_loss, label='Dice') \n",
    "plt.plot(loss, train_iou_loss, label='IOU') \n",
    "plt.plot(loss, train_precision_loss, label='Precision') \n",
    "plt.plot(loss, train_recall_loss, label='Recall') \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('')\n",
    "plt.title('Metrics for training dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7874e",
   "metadata": {},
   "source": [
    "### Draw chart for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.arange(epoch + 1)\n",
    "\n",
    "# Biểu đồ mean loss\n",
    "plt.plot(loss, val_dice_loss, label='Dice') \n",
    "plt.plot(loss, val_iou_loss, label='IOU') \n",
    "plt.plot(loss, val_precision_loss, label='Precision') \n",
    "plt.plot(loss, val_recall_loss, label='Recall') \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('')\n",
    "plt.title('Metrics for validation dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aaf8d1",
   "metadata": {},
   "source": [
    "### Đánh giá trọng số mô hình với tập Validation Dataset (IOU, Precision, Recall, Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Tải trọng số từ checkpoint\n",
    "checkpoint_path = \"/kaggle/working/checkpoint_MEDSAM/best_model_weights_Chocolate_Cyst.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load trọng số vào mô hình\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Đặt mô hình vào chế độ đánh giá\n",
    "model.eval()\n",
    "\n",
    "# Tiếp tục quá trình kiểm tra mô hình như đã thực hiện trước đó\n",
    "test_dice_scores = []\n",
    "test_iou_scores = []\n",
    "test_recall_scores = []\n",
    "test_precision_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                        input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                        multimask_output=False)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        predicted_masks = (torch.sigmoid(outputs['pred_masks']).squeeze() > 0.5).float()\n",
    "        ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "\n",
    "        test_dice_scores.append(dice(predicted_masks, ground_truth_masks))\n",
    "        test_iou_scores.append(iou(predicted_masks, ground_truth_masks))\n",
    "        test_recall_scores.append(recall(predicted_masks, ground_truth_masks))\n",
    "        test_precision_scores.append(precision(predicted_masks, ground_truth_masks))\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\n\")\n",
    "print(f'Validation Dice: {torch.tensor(test_dice_scores).mean().item():.4f}')\n",
    "print(f'Validation IOU: {torch.tensor(test_iou_scores).mean().item():.4f}')\n",
    "print(f'Validation Recall: {torch.tensor(test_recall_scores).mean().item():.4f}')\n",
    "print(f'Validation Precision: {torch.tensor(test_precision_scores).mean().item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4660437,
     "sourceId": 7929258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4772202,
     "sourceId": 8084518,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.30597,
   "end_time": "2024-04-10T18:11:44.668229",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-10T18:07:03.362259",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d5cf8473f6f47cd9248f7aa07bffb49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1e1118b3c3e443cf8becaeb094b61f09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "23716e5e6b374de0a47a518998d00d9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd83c92919aa4c10b4e3effdfa12338b",
       "placeholder": "​",
       "style": "IPY_MODEL_c9b13094f46f4ee7b84d8c98a6cca090",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "3a5e82066b424126b8599179ad075f16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4be448f21139408e89e5411c7560b47e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f0c59cb1e204527a68f4245cde50e64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbb853c615ca47479f06d26c5fc9cc65",
       "max": 466,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_738d7cf3a07f4af587b5082728ae0bce",
       "value": 466
      }
     },
     "56917840741143a198dcc6ff502d7166": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_feccd0bff42a436cb38edfe6f8033ac5",
       "max": 6517,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e1118b3c3e443cf8becaeb094b61f09",
       "value": 6517
      }
     },
     "597679f701bc494694b4a0a8cba507f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9ba07170ee94de3956c5ee38ccb57db",
       "placeholder": "​",
       "style": "IPY_MODEL_3a5e82066b424126b8599179ad075f16",
       "value": "preprocessor_config.json: 100%"
      }
     },
     "5b33f2ba796a45bd93913744961e0949": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5e9b52d4ed64418a9f665fa8c71745fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_597679f701bc494694b4a0a8cba507f1",
        "IPY_MODEL_4f0c59cb1e204527a68f4245cde50e64",
        "IPY_MODEL_6593f3124ba74ce0b3807b4876706198"
       ],
       "layout": "IPY_MODEL_88b153bba683410c841b45080a426690"
      }
     },
     "5ecbbb6195364db7b8b3c5b7dad6dd7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_adf742e91fa24e5d977d1e33bd2b32f8",
       "placeholder": "​",
       "style": "IPY_MODEL_6337e80c5c4f4a5889932d1d6a228ac0",
       "value": " 6.52k/6.52k [00:00&lt;00:00, 593kB/s]"
      }
     },
     "6031bf4ab7434fd6a7afec58c1b06274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4be448f21139408e89e5411c7560b47e",
       "placeholder": "​",
       "style": "IPY_MODEL_5b33f2ba796a45bd93913744961e0949",
       "value": " 375M/375M [00:01&lt;00:00, 310MB/s]"
      }
     },
     "6337e80c5c4f4a5889932d1d6a228ac0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "64f496271ffc4abfbac079f0f54338f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6593f3124ba74ce0b3807b4876706198": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee21dc9eb6274d1ba9bad9f1fe661d8b",
       "placeholder": "​",
       "style": "IPY_MODEL_0d5cf8473f6f47cd9248f7aa07bffb49",
       "value": " 466/466 [00:00&lt;00:00, 38.9kB/s]"
      }
     },
     "738d7cf3a07f4af587b5082728ae0bce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f09b77f51294a4582bba1acee76450f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83a75a78937f4b6c9cbd7d5c85192a48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "87881df61bed4598bbd1e366283aeda4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88b153bba683410c841b45080a426690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a84fa3bb483424586417f3add00ed11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_23716e5e6b374de0a47a518998d00d9e",
        "IPY_MODEL_ba6378f893764407803fc8cf1ce270a8",
        "IPY_MODEL_6031bf4ab7434fd6a7afec58c1b06274"
       ],
       "layout": "IPY_MODEL_64f496271ffc4abfbac079f0f54338f5"
      }
     },
     "a1bbf8549e56432aa163469fe6ef8a76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f09b77f51294a4582bba1acee76450f",
       "placeholder": "​",
       "style": "IPY_MODEL_e773f71c72854116827c029f14435bc6",
       "value": "config.json: 100%"
      }
     },
     "adf742e91fa24e5d977d1e33bd2b32f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba6378f893764407803fc8cf1ce270a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87881df61bed4598bbd1e366283aeda4",
       "max": 375045749,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83a75a78937f4b6c9cbd7d5c85192a48",
       "value": 375045749
      }
     },
     "c9b13094f46f4ee7b84d8c98a6cca090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cd83c92919aa4c10b4e3effdfa12338b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e773f71c72854116827c029f14435bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e9ba07170ee94de3956c5ee38ccb57db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee21dc9eb6274d1ba9bad9f1fe661d8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef30037b03d744b2a43b03309701f684": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbb853c615ca47479f06d26c5fc9cc65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fecb66f478d94d9a8dd0061e691b0fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1bbf8549e56432aa163469fe6ef8a76",
        "IPY_MODEL_56917840741143a198dcc6ff502d7166",
        "IPY_MODEL_5ecbbb6195364db7b8b3c5b7dad6dd7d"
       ],
       "layout": "IPY_MODEL_ef30037b03d744b2a43b03309701f684"
      }
     },
     "feccd0bff42a436cb38edfe6f8033ac5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
